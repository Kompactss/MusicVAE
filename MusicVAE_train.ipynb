{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicVAE_train.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install magenta"
      ],
      "metadata": {
        "id": "n7_QSSt5Cn0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/magenta.git"
      ],
      "metadata": {
        "id": "AZ0DFJr_cXNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/magenta')"
      ],
      "metadata": {
        "id": "4_bEKgyLcrfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/magenta/magenta')"
      ],
      "metadata": {
        "id": "fgWyl3KLCKlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae import data\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim\n",
        "\n",
        "\n",
        "FLAGS = {\n",
        "    'master' : '',\n",
        "    # The TensorFlow master to use.\n",
        "    'examples_path' : '/content/drive/MyDrive/converted_data.tfrecord',\n",
        "    # Path to a TFRecord file of NoteSequence examples. Overrides the config.\n",
        "    'tfds_name' : None,\n",
        "    # TensorFlow Datasets dataset name to use. Overrides the config.\n",
        "    'run_dir' : '/content/drive/MyDrive/groove_2bar_vae',\n",
        "    # Path where checkpoints and summary events will be located during \n",
        "    # training and evaluation. Separate subdirectories `train` and `eval` \n",
        "    # will be created within this directory.\n",
        "    'num_steps' : 200000,\n",
        "    # Number of training steps or `None` for infinite.\n",
        "    'eval_num_batches' : None,\n",
        "    # Number of batches to use during evaluation or `None` for all batches \n",
        "    # in the data source.\n",
        "    'checkpoints_to_keep' : 100,\n",
        "    # Maximum number of checkpoints to keep in `train` mode or 0 for infinite.\n",
        "    'keep_checkpoint_every_n_hours' : 1,\n",
        "    # In addition to checkpoints_to_keep, keep a checkpoint every N hours.'\n",
        "    'mode' : 'train',\n",
        "    # Which mode to use (`train` or `eval`).\n",
        "    'config' : 'nade-drums_2bar_full',\n",
        "    # The name of the config to use.'\n",
        "    'hparams' : '',\n",
        "    # A comma-separated list of `name=value` hyperparameter values to merge '\n",
        "    # with those in the config.\n",
        "    'cache_dataset' : True,\n",
        "    # Whether to cache the dataset in memory for improved training speed. May\n",
        "    # cause memory errors for very large datasets.\n",
        "    'task' : 0,\n",
        "    # The task number for this worker.\n",
        "    'num_ps_tasks' : 0,\n",
        "    # The number of parameter server tasks.\n",
        "    'num_sync_workers' : 0,\n",
        "    # The number of synchronized workers.\n",
        "    'eval_dir_suffix' : 'eval_ckpt',\n",
        "    # Suffix to add to eval output directory.\n",
        "    'log' : 'INFO'\n",
        "    # The threshold for what messages will be logged:\n",
        "    # DEBUG, INFO, WARN, ERROR, or FATAL.\n",
        "}"
      ],
      "metadata": {
        "id": "T_IAgaa3t9yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Should not be called from within the graph to avoid redundant summaries.\n",
        "def _trial_summary(hparams, examples_path, output_dir):\n",
        "  \"\"\"Writes a tensorboard text summary of the trial.\"\"\"\n",
        "\n",
        "  examples_path_summary = tf.summary.text(\n",
        "      'examples_path', tf.constant(examples_path, name='examples_path'),\n",
        "      collections=[])\n",
        "\n",
        "  hparams_dict = hparams.values()\n",
        "\n",
        "  # Create a markdown table from hparams.\n",
        "  header = '| Key | Value |\\n| :--- | :--- |\\n'\n",
        "  keys = sorted(hparams_dict.keys())\n",
        "  lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n",
        "  hparams_table = header + '\\n'.join(lines) + '\\n'\n",
        "\n",
        "  hparam_summary = tf.summary.text(\n",
        "      'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n",
        "\n",
        "'''\n",
        "  with tf.Session() as sess:\n",
        "    writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n",
        "    writer.add_summary(examples_path_summary.eval())\n",
        "    writer.add_summary(hparam_summary.eval())\n",
        "    writer.close()\n",
        "'''\n",
        "\n",
        "def _get_input_tensors(dataset, config):\n",
        "  \"\"\"Get input tensors from dataset.\"\"\"\n",
        "  batch_size = config.hparams.batch_size\n",
        "  iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "  (input_sequence, output_sequence, control_sequence,\n",
        "   sequence_length) = iterator.get_next()\n",
        "  input_sequence.set_shape(\n",
        "      [batch_size, None, config.data_converter.input_depth])\n",
        "  output_sequence.set_shape(\n",
        "      [batch_size, None, config.data_converter.output_depth])\n",
        "  if not config.data_converter.control_depth:\n",
        "    control_sequence = None\n",
        "  else:\n",
        "    control_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.control_depth])\n",
        "  sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "\n",
        "  return {\n",
        "      'input_sequence': input_sequence,\n",
        "      'output_sequence': output_sequence,\n",
        "      'control_sequence': control_sequence,\n",
        "      'sequence_length': sequence_length\n",
        "  }\n",
        "\n",
        "\n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep=5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "  \"\"\"Train loop.\"\"\"\n",
        "  tf.gfile.MakeDirs(train_dir)\n",
        "  is_chief = (task == 0)\n",
        "  if is_chief:\n",
        "    _trial_summary(\n",
        "        config.hparams, config.train_examples_path or config.tfds_name,\n",
        "        train_dir)\n",
        "  with tf.Graph().as_default():\n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "        num_ps_tasks, merge_devices=True)):\n",
        "\n",
        "      model = config.model\n",
        "      model.build(config.hparams,\n",
        "                  config.data_converter.output_depth,\n",
        "                  is_training=True)\n",
        "\n",
        "      optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "      hooks = []\n",
        "      if num_sync_workers:\n",
        "        optimizer = tf.train.SyncReplicasOptimizer(\n",
        "            optimizer,\n",
        "            num_sync_workers)\n",
        "        hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "      grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n",
        "      global_norm = tf.global_norm(grads)\n",
        "      tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "      if config.hparams.clip_mode == 'value':\n",
        "        g = config.hparams.grad_clip\n",
        "        clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "      elif config.hparams.clip_mode == 'global_norm':\n",
        "        clipped_grads = tf.cond(\n",
        "            global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "            lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "            lambda: [tf.zeros(tf.shape(g)) for g in grads])\n",
        "      else:\n",
        "        raise ValueError(\n",
        "            'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n",
        "      train_op = optimizer.apply_gradients(\n",
        "          list(zip(clipped_grads, var_list)),\n",
        "          global_step=model.global_step,\n",
        "          name='train_step')\n",
        "\n",
        "      logging_dict = {'global_step': model.global_step,\n",
        "                      'loss': model.loss}\n",
        "\n",
        "      hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "      if num_steps:\n",
        "        hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "\n",
        "      scaffold = tf.train.Scaffold(\n",
        "          saver=tf.train.Saver(\n",
        "              max_to_keep=checkpoints_to_keep,\n",
        "              keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n",
        "      tf_slim.training.train(\n",
        "          train_op=train_op,\n",
        "          logdir=train_dir,\n",
        "          scaffold=scaffold,\n",
        "          hooks=hooks,\n",
        "          save_checkpoint_secs=60,\n",
        "          master=master,\n",
        "          is_chief=is_chief)\n",
        "\n",
        "\n",
        "def evaluate(train_dir,\n",
        "             eval_dir,\n",
        "             config,\n",
        "             dataset_fn,\n",
        "             num_batches,\n",
        "             master=''):\n",
        "  \"\"\"Evaluate the model repeatedly.\"\"\"\n",
        "  tf.gfile.MakeDirs(eval_dir)\n",
        "\n",
        "  _trial_summary(\n",
        "      config.hparams, config.eval_examples_path or config.tfds_name, eval_dir)\n",
        "  with tf.Graph().as_default():\n",
        "    model = config.model\n",
        "    model.build(config.hparams,\n",
        "                config.data_converter.output_depth,\n",
        "                is_training=False)\n",
        "\n",
        "    eval_op = model.eval(\n",
        "        **_get_input_tensors(dataset_fn().take(num_batches), config))\n",
        "\n",
        "    hooks = [\n",
        "        tf_slim.evaluation.StopAfterNEvalsHook(num_batches),\n",
        "        tf_slim.evaluation.SummaryAtEndHook(eval_dir)\n",
        "    ]\n",
        "    tf_slim.evaluation.evaluate_repeatedly(\n",
        "        train_dir,\n",
        "        eval_ops=eval_op,\n",
        "        hooks=hooks,\n",
        "        eval_interval_secs=60,\n",
        "        master=master)\n",
        "\n",
        "\n",
        "def run(config_map,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        file_reader=tf.python_io.tf_record_iterator):\n",
        "  \"\"\"Load model params, save config file and start trainer.\n",
        "  Args:\n",
        "    config_map: Dictionary mapping configuration name to Config object.\n",
        "    tf_file_reader: The tf.data.Dataset class to use for reading files.\n",
        "    file_reader: The Python reader to use for reading files.\n",
        "  Raises:\n",
        "    ValueError: if required flags are missing or invalid.\n",
        "  \"\"\"\n",
        "  if not FLAGS['run_dir']:\n",
        "    raise ValueError('Invalid run directory: %s' % FLAGS['run_dir'])\n",
        "  run_dir = os.path.expanduser(FLAGS['run_dir'])\n",
        "  train_dir = os.path.join(run_dir, 'train')\n",
        "\n",
        "  if FLAGS['mode'] not in ['train', 'eval']:\n",
        "    raise ValueError('Invalid mode: %s' % FLAGS['mode'])\n",
        "\n",
        "  if FLAGS['config'] not in config_map:\n",
        "    raise ValueError('Invalid config: %s' % FLAGS['config'])\n",
        "  config = config_map[FLAGS['config']]\n",
        "  if FLAGS['hparams']:\n",
        "    config.hparams.parse(FLAGS['hparams'])\n",
        "  config_update_map = {}\n",
        "  if FLAGS['examples_path']:\n",
        "    config_update_map['%s_examples_path' % FLAGS['mode']] = os.path.expanduser(\n",
        "        FLAGS['examples_path'])\n",
        "  if FLAGS['tfds_name']:\n",
        "    if FLAGS['examples_path']:\n",
        "      raise ValueError(\n",
        "          'At most one of --examples_path and --tfds_name can be set.')\n",
        "    config_update_map['tfds_name'] = FLAGS['tfds_name']\n",
        "    config_update_map['eval_examples_path'] = None\n",
        "    config_update_map['train_examples_path'] = None\n",
        "  config = configs.update_config(config, config_update_map)\n",
        "  if FLAGS['num_sync_workers']:\n",
        "    config.hparams.batch_size //= FLAGS['num_sync_workers']\n",
        "\n",
        "  if FLAGS['mode'] == 'train':\n",
        "    is_training = True\n",
        "  elif FLAGS['mode'] == 'eval':\n",
        "    is_training = False\n",
        "  else:\n",
        "    raise ValueError('Invalid mode: {}'.format(FLAGS['mode']))\n",
        "\n",
        "  def dataset_fn():\n",
        "    return data.get_dataset(\n",
        "        config,\n",
        "        tf_file_reader=tf_file_reader,\n",
        "        is_training=is_training,\n",
        "        cache_dataset=FLAGS['cache_dataset'])\n",
        "\n",
        "  if is_training:\n",
        "    train(\n",
        "        train_dir,\n",
        "        config=config,\n",
        "        dataset_fn=dataset_fn,\n",
        "        checkpoints_to_keep=FLAGS['checkpoints_to_keep'],\n",
        "        keep_checkpoint_every_n_hours=FLAGS['keep_checkpoint_every_n_hours'],\n",
        "        num_steps=FLAGS['num_steps'],\n",
        "        master=FLAGS['master'],\n",
        "        num_sync_workers=FLAGS['num_sync_workers'],\n",
        "        num_ps_tasks=FLAGS['num_ps_tasks'],\n",
        "        task=FLAGS['task'])\n",
        "  else:\n",
        "    num_batches = FLAGS['eval_num_batches'] or data.count_examples(\n",
        "        config.eval_examples_path,\n",
        "        config.tfds_name,\n",
        "        config.data_converter,\n",
        "        file_reader) // config.hparams.batch_size\n",
        "    eval_dir = os.path.join(run_dir, 'eval' + FLAGS['eval_dir_suffix'])\n",
        "    evaluate(\n",
        "        train_dir,\n",
        "        eval_dir,\n",
        "        config=config,\n",
        "        dataset_fn=dataset_fn,\n",
        "        num_batches=num_batches,\n",
        "        master=FLAGS['master'])"
      ],
      "metadata": {
        "id": "-cl5WeiNeAtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(FLAGS['log'])\n",
        "run(configs.CONFIG_MAP)"
      ],
      "metadata": {
        "id": "sb_U0EYkE4oX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}